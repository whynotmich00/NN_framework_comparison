<!DOCTYPE html>
<html lang="it">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>PyTorch - Libreria per Reti Neurali</title>
    <link rel="stylesheet" href="../../css/style.css">
    <link rel="icon" href="../../images/favicon.ico" type="image/x-icon">
    <link rel="shortcut icon" href="favicon.ico" type="image/x-icon">
</head>
<body>
    <header>
        <div class="container">
            <div class="header-content">
                <div>
                    <h1>PyTorch</h1>
                    <p>Framework flessibile con esecuzione dinamica per deep learning</p>
                </div>
            </div>
        </div>
    </header>
    
    <div class="container">
        <a href="../../index.html" class="btn btn-back">← Torna alla Home</a>
        <a href="pytorch_training.html" class="btn btn-tutorial">Tutorial: Addestramento MLP su MNIST →</a>
        
        <!-- SEZIONE 1: Backend e Paradigma di Grafo Dinamico -->
        <div class="content-section">
            <h2>Il Backend di PyTorch e il Paradigma del Grafo Dinamico</h2>
            
            <p>PyTorch è una libreria di deep learning open source sviluppata principalmente da Facebook's AI Research lab (FAIR). A differenza di altri framework come TensorFlow (nella sua versione 1.x), PyTorch utilizza un paradigma di grafo dinamico (define-by-run) anziché un grafo statico (define-and-run).</p>
            
            <h3>Backend di PyTorch: C++ e CUDA</h3>
            <p>PyTorch è costruito su un backend C++ ad alte prestazioni chiamato ATen, che a sua volta si basa su una libreria BLAS ottimizzata come MKL (Math Kernel Library) di Intel. Per l'accelerazione GPU, PyTorch sfrutta CUDA, una piattaforma di computing parallelo e un modello di programmazione sviluppato da NVIDIA.</p>
            
            <p>Il backend di PyTorch include:</p>
            <ul>
                <li><strong>LibTorch</strong>: il core C++ di PyTorch che gestisce tutte le operazioni tensoriali</li>
                <li><strong>cuDNN</strong>: una libreria di NVIDIA per implementazioni ottimizzate di operazioni di deep learning su GPU</li>
                <li><strong>ATen</strong>: un framework tensoriale che fornisce un'interfaccia tensor e operazioni matematiche</li>
            </ul>
            
            <h3>Perché il Paradigma di Grafo Dinamico?</h3>
            <p>PyTorch ha fatto una scelta esplicita di utilizzare un paradigma di grafo computazionale dinamico per diversi motivi chiave:</p>
            
            <ol>
                <li><strong>Intuitività e Naturalezza</strong>: Con un grafo dinamico, il codice viene eseguito passo dopo passo, proprio come il normale codice Python. Questo rende più intuitivo il debugging e la comprensione del flusso del programma.</li>
                <li><strong>Flessibilità</strong>: I modelli possono cambiare comportamento dinamicamente durante l'esecuzione. Questo è essenziale per implementare facilmente modelli con flusso di controllo dipendente dai dati, come RNN con lunghezza variabile o reti con architetture condizionali.</li>
                <li><strong>Debugging Semplificato</strong>: Poiché il codice viene eseguito in modo imperativo, è possibile utilizzare gli strumenti di debugging standard di Python come print, pdb o IDE.</li>
                <li><strong>Ricerca e Prototipazione</strong>: La natura dinamica è particolarmente adatta alla ricerca, dove gli algoritmi e le architetture cambiano frequentemente ed è necessario sperimentare rapidamente.</li>
            </ol>
            
            <h3>Come Funziona il Grafo Dinamico</h3>
            <p>In PyTorch, il grafo computazionale viene costruito durante l'esecuzione (on-the-fly):</p>
            <ol>
                <li>Ogni operazione viene eseguita immediatamente quando viene chiamata</li>
                <li>Durante l'esecuzione, PyTorch registra automaticamente le operazioni in un grafo per il calcolo del gradiente (autograd)</li>
                <li>Questo grafo esiste solo per la passata forward corrente e viene ricreato per ogni nuova passata</li>
            </ol>
            
            <p>Questo contrasta con l'approccio statico dove il grafo viene definito prima dell'esecuzione e poi eseguito ripetutamente. Il paradigma dinamico di PyTorch è più simile al modo in cui i programmatori Python pensano e lavorano normalmente.</p>
        </div>
        
        <!-- SEZIONE 3: Segnaposto per la sezione sulla velocità di PyTorch -->
        <div class="content-section">
            <h2>Velocità e Prestazioni di PyTorch</h2>
            <p>Questa sezione verrà sviluppata successivamente. Tratterà la velocità di PyTorch, le ottimizzazioni e i confronti di performance con altri framework.</p>
        </div>
    </div>
    
    <footer>
        <div class="container">
            <p>© 2025 - Guida alle Librerie per Reti Neurali</p>
        </div>
    </footer>
</body>
</html>