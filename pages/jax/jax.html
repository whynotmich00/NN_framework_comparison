<!DOCTYPE html>
<html lang="it">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>JAX - Libreria per Reti Neurali</title>
    <link rel="stylesheet" href="../../css/style.css">
    <link rel="icon" href="../../images/favicon.ico" type="image/x-icon">
    <link rel="shortcut icon" href="favicon.ico" type="image/x-icon">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script src="../../js/main.js"></script>
    <style>
        .tab {
          padding: 10px 20px;
          margin-right: 5px;
          background: #ddd;
          border-radius: 5px 5px 0 0;
          cursor: pointer;
        }
    
        .tab.active {
          background: #fff;
          font-weight: bold;
          border-bottom: 2px solid white;
        }
    
        .tab-content {
          background: #fff;
          border: 1px solid #ddd;
          border-radius: 0 5px 5px 5px;
          padding: 20px;
          display: none;
        }
    
        .tab-content.active {
          display: block;
        }
    
        pre {
          margin: 0;
          background: #f0f0f0;
          padding: 10px;
          border-radius: 5px;
          overflow-x: auto;
        }
        .tabs {
        display: flex;
        flex-direction: row; /* Questo assicura che i tab siano in orizzontale */
        margin-bottom: 0;
        border-bottom: 1px solid #ddd;
        }
    
        .tab-content {
        position: relative; /* Necessario per posizionare il pulsante copia */
        }
    
        .copy-button {
        position: absolute;
        top: 10px;
        right: 10px;
        padding: 5px 10px;
        background: #4CAF50;
        color: white;
        border: none;
        border-radius: 4px;
        cursor: pointer;
        z-index: 10; /* Assicura che il pulsante sia sopra il codice */
        }
    
        .copy-button:hover {
        background: #45a049;
        }
        
        /* Stili per la sezione dell'ecosistema */
        .library-cards {
            display: flex;
            flex-wrap: wrap;
            gap: 20px;
            margin-top: 20px;
            justify-content: space-between;
        }
        
        .library-card {
            background-color: #ffffff;
            border-radius: 8px;
            box-shadow: 0 4px 10px rgba(0, 0, 0, 0.1);
            overflow: hidden;
            transition: transform 0.3s ease, box-shadow 0.3s ease;
            width: calc(33.333% - 14px);
            min-width: 280px;
            text-decoration: none;
            color: inherit;
            display: flex;
            flex-direction: column;
        }
        
        .library-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 8px 20px rgba(0, 0, 0, 0.15);
        }
        
        .card-image {
            height: 160px;
            overflow: hidden;
            display: flex;
            align-items: center;
            justify-content: center;
            background-color: #f8f9fa;
        }
        
        .card-image img {
            max-width: 80%;
            max-height: 80%;
            object-fit: contain;
        }
        
        .card-content {
            padding: 16px;
            flex-grow: 1;
            display: flex;
            flex-direction: column;
        }
        
        .card-content h3 {
            margin-top: 0;
            margin-bottom: 10px;
            color: #1a73e8;
            font-size: 1.4em;
        }
        
        .card-content p {
            margin-bottom: 0;
            font-size: 0.95em;
            line-height: 1.5;
        }
        
        /* Responsive design */
        @media (max-width: 900px) {
            .library-card {
                width: calc(50% - 10px);
            }
        }
        
        @media (max-width: 600px) {
            .library-cards {
                flex-direction: column;
            }
            
            .library-card {
                width: 100%;
            }
        }
    </style>
</head>
<body>
    <header>
        <div class="container">
            <div class="header-content">
                <div>
                    <h1>JAX</h1>
                    <p>Framework per differenziazione automatica e calcolo ad alte prestazioni</p>
                </div>
            </div>
        </div>
    </header>
    
    <div class="container">
        <a href="../../index.html" class="btn btn-back">← Torna alla Home</a>
        <a href="jax_fundamentals.html" class="btn btn-tutorial">VMAP, GRAD, JIT: Le tre colonne portanti di JAX →</a>
        <a href="jax_training.html" class="btn btn-tutorial">Tutorial: Addestramento MLP su MNIST →</a>
        <a href="jax_advanced.html" class="btn btn-tutorial">Avanzato: Differenziazione Automatica e Allenamento Distribuito →</a>
        
        <!-- SEZIONE 1: Introduzione, Backend e Architettura di JAX -->
        <div class="content-section">
            <h2>Introduzione a JAX (Numpy on steroids)</h2>
            <p><a href="https://github.com/google/jax" target="_blank">JAX</a> è un framework di calcolo numerico sviluppato da Google Research che combina <a href="https://numpy.org/" target="_blank">NumPy</a> con la <a href="https://en.wikipedia.org/wiki/Automatic_differentiation" target="_blank">differenziazione automatica</a> e l'accelerazione hardware. La sua familiarità con la sintassi di NumPy
                lo rende comprensibile e facile da usare rendendo il percorso di apprendimento più semplice per un'ampia fetta di praticanti che si è già approcciato al calcolo numerico in Python. Quello che alcuni sviluppatori di Google hanno fatto è stato prendere il
                codice sorgente aperto di NumPy e scriverne una versione apparentemente identica, ma che permette di essere eseguita su vari acceleratori come <a href="https://en.wikipedia.org/wiki/Graphics_processing_unit" target="_blank">GPU</a> e simili (vedi <code><a href="https://jax.readthedocs.io/en/latest/jax.numpy.html" target="_blank">jax.numpy</a></code>).
                Anche se spesso lavorare con JAX implica scrivere codice molto simili a quello che scriveremmo in NumPy, JAX è molto più di una semplice libreria accelerata ispirata a questa. Infatti, JAX offre anche la differenziazione automatica (<code><a href="https://jax.readthedocs.io/en/latest/jax.html#jax.grad" target="_blank">jax.grad</a></code>) e la compilazione just-in-time (<code><a href="https://jax.readthedocs.io/en/latest/jax.html#jax.jit" target="_blank">jax.jit</a></code>) per ottimizzare le prestazioni del codice.
                Queste funzioni vengono esplorate nel dettaglio nella pagina a loro dedicata <a href="jax_fundamentals.html">"VMAP, GRAD, JIT: Le tre colonne portanti di JAX"</a>. Le potenzialità di JAX non si fermano qui, nella sua libreria possiamo trovare numerose altre feature che, per esempio, ci permettono di scrivere
                kernel per GPU e TPU senza l'utilizzo di <a href="https://developer.nvidia.com/cuda-toolkit" target="_blank">CUDA</a> o <a href="https://www.khronos.org/opencl/" target="_blank">OpenCL</a> (<code><a href="https://jax.readthedocs.io/en/latest/pallas/index.html" target="_blank">jax.pallas</a></code>) o parallelizzare il calcolo su più dispositivi modificando di poco il codice che si scriverebbe normalmente.
                Oltre NumPy anche <a href="https://docs.jax.dev/en/latest/jax.scipy.html" target="_blank">SciPy</a> è stata inglobata in JAX, permettendo di utilizzare molte funzioni avanzate di calcolo scientifico e statistico in maniera accelerata.
            </p>
            <p>Le caratteristiche essenziali di JAX che ci aiutano a capire il suo funzionamento sono:</p>
                <ul>
                    <li>JAX fornisce un'interfaccia unificata simile a NumPy per eseguire calcoli su CPU, GPU o TPU, in ambienti locali o distribuiti.</li>
                    <li>JAX offre la compilazione Just-In-Time (JIT) integrata tramite Open XLA, un ecosistema open-source di compilatori per l'apprendimento automatico.</li>
                    <li>Le funzioni di JAX supportano la valutazione efficiente dei gradienti grazie alle sue trasformazioni di differenziazione automatica.</li>
                    <li>Le funzioni di JAX possono essere automaticamente vettorializzate per mappare in modo efficiente sugli array che rappresentano batch di input.</li>
                </ul>
        </div>

        <div class="content-section">
            <h1>La filosofia di JAX</h1>
            
            <p>
                JAX nasce con una filosofia profondamente radicata nella <span class="highlight">programmazione funzionale</span>, 
                distinguendosi nettamente dall'approccio imperativo di framework come PyTorch. Questa scelta come vedremo ha delle valide
                motivazioni dietro ma determina anche una piccola barriera all'entrata per chi si approccia per la prima volta a JAX ed è abituato
                al classico Python. Python, infatti, è un linguaggio orientato agli oggetti. La programmazione ad oggetti e funzionale sono due paradigmi
                di programmazione che differiscono nel loro modo di gestire il flusso dei dati e le "azioni/trasformazioni" che modificano tali dati in gergo si riferisce a questi come stato del programma.
                Il primo si basa su oggetti, che sono entità che combinano dati (attributi) e comportamento (metodi), mentre il secondo si concentra su funzioni (o composizione di queste)
                che operano senza modificare lo stato del programma.
            </p>
            <p>Quindi, alcune conseguenze sono:</p>
            <ul>
                <li>JAX è costruito attorno al concetto di <strong>funzioni pure</strong>: funzioni che, dato lo stesso input, producono sempre lo stesso output senza effetti collaterali</li>
                <li>Evita mutazioni di stato: le operazioni restituiscono nuovi array invece di modificare quelli esistenti</li>
                <li>Tutti gli array JAX sono immutabili (non modificabili)</li>
            </ul>
            
            <!-- Implementazione del tab system per il confronto Numpy vs JAX -->
            <div class="tabs-container">
                <div class="tabs">
                    <div class="tab active" data-tab="numpy-imperative">NumPy (imperativo)</div>
                    <div class="tab" data-tab="jax-functional">JAX (funzionale)</div>
                </div>
                
                <div id="numpy-imperative" class="tab-content active">
                    <pre><code class="language-python">import numpy as np
array = np.zeros(10)
array[0] = 1  # Modifica l'array esistente</code></pre>
                    <button class="copy-button" onclick="copyCode(this)">Copia</button>
                </div>
                
                <div id="jax-functional" class="tab-content">
                    <pre><code class="language-python">import jax.numpy as jnp
array = jnp.zeros(10)
# Non è possibile fare array[0] = 1
# Invece, creiamo un nuovo array:
array = array.at[0].set(1)</code></pre>
                    <button class="copy-button" onclick="copyCode(this)">Copia</button>
                </div>
            </div>
            
            <h2>Trasformazioni e composizioni di funzioni</h2>
            <div>
                <p>Come detto precedentemente in programmazione funzionale capita abitualmente di comporre funzioni. Matematicamente 
                scrivere una composizione di funzioni senza valutarle per uno specifico input è un'operazione semplice che 
                conserva il loro significato semantico. Fare ciò in un programma può diventare complicato, un esempio.
                </p>
                <pre><code class="language-python">import numpy as np
# se volessi creare una composizione di due funzioni sqrt e square in un unica funzione: composizione,
# il seguente codice mi darebbe errore, perchè square non può accettare altre funzioni in input
try:
    composition = np.square(np.sqrt)
except:
    print("Errore!")

# potremmo usare la funzione anonima lambda, usatissima in JAX, per ovviare a questo problema
composition = lambda x: np.square(np.sqrt(x))
x = 10
print(f"Ora valuto la funzione in {x}: {composition(x)}")
                </code></pre>
                    
                                <button class="copy-button" onclick="copyCode(this)">Copia</button>
            </div>
            <p>
                Quindi una soluzione per programmare funzionalemente in Python è astreando il calcolo con la funzione anonima lambda. Per alcune operazioni
                importanti JAX introduce il concetto di "trasformazioni di funzioni di ordine superiore" ossia funzioni che accettano come input altre funzioni.
            </p>
            <p>
                In particolare le funzioni più importanti che JAX mette a disposizione sono esplorate in <a href="jax_fundamentals.html">"VMAP, GRAD, JIT: Le tre colonne portanti di JAX"</a>.
                Di seguito le presentiamo in breve:
            </p>
            <ul>
                <li><code>jit</code>: compila funzioni con XLA per esecuzione accelerata</li>
                <li><code>grad</code>: calcola automaticamente gradienti</li>
                <li><code>vmap</code>: vettorizza funzioni su batch</li>
                <li><code>shard_map</code>: parallelizzazione manuale di funzioni su più dispositivi</li>
            </ul>
            
            <p>Queste trasformazioni possono essere composte, a loro volta, in modo elegante:</p>
            <div>
            <pre><code class="language-python">import jax
import jax.numpy as jnp

def loss_fn(params, x, y):
    y_pred = model(params, x)
    return jnp.mean((y_pred - y)**2)

# Compone trasformazioni in modo semplice
training_step = jax.jit(jax.grad(loss_fn))</code></pre>

            <button class="copy-button" onclick="copyCode(this)">Copia</button>
            </div>
            <p>
                Questo approccio alla programmazione ha diversi vantaggi. I più ovvi sono:
            </p>
            <ul>
                <li>Favorisce la composizione di funzioni più piccole per costruire sistemi complessi</li>
                <li>La trasparenza referenziale (si veda esempio) garantisce che le funzioni possano essere sostituite con i loro valori</li>
                <li>Incoraggia uno stile di programmazione più matematico e dichiarativo</li>
            </ul>
            <div class="tabs-container">
                <div class="tabs">
                    <div class="tab active" data-tab="composizione-funzioni">Composizione di Funzioni</div>
                    <div class="tab" data-tab="trasparenza-referenziale">Trasparenza Referenziale</div>
                    <div class="tab" data-tab="non-trasparenza-referenziale">Funzione con stato interno</div>
                </div>
            <div id="composizione-funzioni" class="tab-content active">
                <pre><code class="language-python">def double(x):
    return x * 2

def add_one(x):
    return x + 1

# Composizione di funzioni
transform = jax.jit(jax.vmap(lambda x: add_one(double(x))))

# Applicazione a un batch
batch = jnp.array([1, 2, 3, 4])
result = transform(batch)  # [3, 5, 7, 9]</code></pre>
            <button class="copy-button" onclick="copyCode(this)">Copia</button>

            </div>
            
            <div id="trasparenza-referenziale" class="tab-content">
                <pre><code class="language-python"># Funzione referenzialmente trasparente
# Funzione referenzialmente trasparente
def add(a, b):
    return a + b

x = add(2, 3)  # x = 5
y = add(2, 3)  # y = 5

# Possiamo sostituire add(2, 3) con 5 ovunque senza cambiare il comportamento
                    </code></pre>
                <button class="copy-button" onclick="copyCode(this)">Copia</button>
            </div>

            <div class="tab-content" id="non-trasparenza-referenziale">
                <pre><code class="language-python">counter = 0

# Funzione NON referenzialmente trasparente
def increment():
    global counter
    counter += 1
    return counter

a = increment()  # a = 1
b = increment()  # b = 2

# Non possiamo sostituire increment() con il suo valore perché cambia ogni volta
                </code></pre>
                <button class="copy-button" onclick="copyCode(this)">Copia</button>
            </div>
            </div>

            <p>
                Ora che conosciamo la filosofia e l'approccio di JAX, torniamo all'utilizzo che ci interessa di più. Allenare una rete neurale.
                Il design appena descritto di JAX spinge forzatamente al "Principio della separazione tra dati e computazione", nell'allenare un modello
                ci troveremo di fronte ad un codice in cui:
            </p>
            
            <ul>
                <li>I modelli sono rappresentati come funzioni pure che operano su parametri</li>
                <li>I parametri sono passati esplicitamente, non incapsulati in oggetti come in PyTorch</li>
                <li>Si favorisce l'architettura "dati dentro, dati fuori" rispetto all'approccio ad oggetti</li>
            </ul>
            
            <!-- Implementazione del tab system per il confronto PyTorch vs JAX -->
            <div class="tabs-container">
                <div class="tabs">
                    <div class="tab active" data-tab="pytorch-oop">PyTorch (orientato agli oggetti)</div>
                    <div class="tab" data-tab="jax-functional-model">JAX (funzionale)</div>
                </div>
                
                <div id="pytorch-oop" class="tab-content active">
                    <pre><code class="language-python">import torch

class Model(torch.nn.Module):
    def __init__(self):
        super().__init__()
        self.layer = torch.nn.Linear(10, 1)
    
    def forward(self, x):
        return self.layer(x)

model = Model()
output = model(input_data)</code></pre>
                    <button class="copy-button" onclick="copyCode(this)">Copia</button>
                </div>
                
                <div id="jax-functional-model" class="tab-content">
                    <pre><code class="language-python">import jax
import jax.numpy as jnp
from jax import random

def init_params(key):
    key, subkey = random.split(key)
    W = random.normal(subkey, (10, 1))
    b = jnp.zeros(1)
    return {"weights": W, "bias": b}

def model(params, x):
    return jnp.dot(x, params["weights"]) + params["bias"]

key = random.PRNGKey(42)
params = init_params(key)
output = model(params, input_data)</code></pre>
                    <button class="copy-button" onclick="copyCode(this)">Copia</button>
                </div>
            </div>
        </div>

        <div class="content-section">
            <h2>Il Backend di JAX e la sua Architettura</h2>
            
            <p>Ora ci addentreremo di più sul funzionamento interno di JAX, è fondametale che
                si conoscano già i concetti precedentemente esposti. 
            </p>
            <p>
                Il nome "JAX" sta per "Just After eXecution" (subito dopo l'esecuzione), un riferimento al suo approccio di
                tracciamento e compilazione del codice. JAX, infatti, è costruito su una serie di componenti che lavorano insieme
                per fornire le sue funzionalità principali:
            </p>
            <ol>
                <li><strong><a href="https://www.tensorflow.org/xla" target="_blank">XLA (Accelerated Linear Algebra)</a></strong>: Un compilatore e runtime specializzato per algebra lineare accelerata, sviluppato inizialmente per TensorFlow.
                    XLA ottimizza i calcoli per esecuzione su hardware specifico (CPU, <a href="https://en.wikipedia.org/wiki/Graphics_processing_unit" target="_blank">GPU</a>, <a href="https://cloud.google.com/tpu" target="_blank">TPU</a>).</li>
                
                <li><strong>Tracciamento e trasformazione di funzioni</strong>: JAX trasforma funzioni Python in rappresentazioni che possono essere analizzate, ottimizzate e compilate.</li>
                
                <li><strong>Differenziazione automatica</strong>: JAX implementa sia la differenziazione in avanti che all'indietro, permettendo di calcolare gradienti esatti di funzioni.</li>
                
                <li><strong>Interfaccia NumPy</strong>: come sappiamo è fondamentale per JAX offrire un'API in cui sono messe a disposizione un buon numero di funzioni, grazie 
                    all'interfaccia di NumPy non bisogna reinventare la ruota.</li>
            </ol>
            
            <h3>Come Funziona JAX "Under the Hood"</h3>
            <p>JAX opera attraverso un processo multifase che permette di ottimizzare e accelerare il codice Python:</p>
            
            <h4>1. Tracciamento e Rappresentazione Funzionale</h4>
            <p>Quando si applica una trasformazione JAX (come <code><a href="https://jax.readthedocs.io/en/latest/jax.html#jax.jit" target="_blank">jit</a></code>, <code><a href="https://jax.readthedocs.io/en/latest/jax.html#jax.grad" target="_blank">grad</a></code>, o <code><a href="https://jax.readthedocs.io/en/latest/jax.html#jax.vmap" target="_blank">vmap</a></code>) a una funzione, JAX esegue queste operazioni:</p>
            <ul>
                <li>Traccia la funzione con valori concreti per capire quali operazioni vengono eseguite</li>
                <li>Costruisce un grafo computazionale chiamato "jaxpr" (JAX expression)</li>
                <li>Questa rappresentazione cattura l'essenza matematica della funzione, indipendentemente dagli aspetti specifici di Python</li>
            </ul>

            <p>Il jaxpr è una rappresentazione del grafo computazionale che mostra le operazioni e le dipendenze tra di esse. Fondamentale: Rappresenta una forma più astratta e funzionale del codice, in cui i dettagli principali
                sono i tipi e le dimensioni dei dati e le operazioni della computazione. Questa rappresentazione è simile a un grafo di flusso di dati, dove i nodi rappresentano le operazioni e gli archi rappresentano i dati che fluiscono tra di esse. Il jaxpr è una rappresentazione intermedia che JAX utilizza per ottimizzare e compilare il codice.
                Si noti che questa forma di rappresentazione è molto diversa da quella che si trova per una normale funzione Python, dove il codice è scritto in modo imperativo e le operazioni sono eseguite in sequenza.</p>
                Ecco un esempio di jaxpr per una funzione semplice:</p>

            <div class="example-code">
                <pre><code class="language-python">import jax
import jax.numpy as jnp

def simple_function(x):
    return jnp.sum(jnp.square(x))
# Create input data
x = jnp.array([1.0, 2.0, 3.0, 4.0])
# Get the value and jaxpr
value = simple_function(x)
jax.make_jaxpr(simple_function)(x)</code></pre>
                <button class="copy-button" onclick="copyCode(this)">Copia</button>
            </div>
            <div class="output-block">
                <pre><code class="language-output">{ lambda ; a:f32[4]. let
b:f32[4] = integer_pow[y=2] a
c:f32[] = reduce_sum[axes=(0,)] b
in (c,) }</code></pre>
                            </div>
            
            <h4>2. Trasformazione</h4>
            <p>Il jaxpr può essere trasformato in vari modi:</p>
            <ul>
                <li><strong><a href="https://jax.readthedocs.io/en/latest/jax.html#jax.grad" target="_blank">grad</a></strong>: Calcola i gradienti di una funzione rispetto ai suoi input</li>
                <li><strong><a href="https://jax.readthedocs.io/en/latest/jax.html#jax.vmap" target="_blank">vmap</a></strong>: Vettorizza una funzione lungo una dimensione aggiuntiva</li>
                <li><strong><a href="https://jax.readthedocs.io/en/latest/jax.html#jax.jit" target="_blank">jit</a></strong>: Compila una funzione per esecuzione ottimizzata</li>
                <li><strong><a href="https://docs.jax.dev/en/latest/_autosummary/jax.experimental.shard_map.shard_map.html#jax.experimental.shard_map.shard_map" target="_blank">shard_map</a></strong>: Parallelizzazione manuale di una funzione su dispositivi multipli</li>
            </ul>
            
            <h4>3. Compilazione con XLA</h4>
            <p>Il jaxpr trasformato viene compilato tramite <a href="https://www.tensorflow.org/xla" target="_blank">XLA</a>:</p>
            <ul>
                <li>XLA analizza il grafo computazionale e applica ottimizzazioni come fusione delle operazioni e riallocazione della memoria</li>
                <li>Genera codice specifico per l'hardware di destinazione (CPU, GPU, o TPU) e ottimizzato in base al numero di dispositivi disponibile (jit è capace di parallelizzazione automatica)</li>
                <li>Il codice compilato viene messo in cache per riutilizzarlo con input di tipo e forma simile</li>
            </ul>
            
            <h4>4. Esecuzione</h4>
            <p>Quando la funzione compilata viene chiamata con input concreti, come i dati su cui stiamo allenando il modello:</p>
            <ul>
                <li>JAX utilizza il codice compilato se disponibile in cache e se i dati corrispondono alle caratteristiche con cui inizialmente è stata compilata
                    la funzione, in particolare per tipo e dimensioni
                </li>
                <li>In caso contrario, traccia e compila nuovamente</li>
                <li>I risultati vengono restituiti come array JAX (simili a ndarray di NumPy, ma immutabili)</li>
            </ul>

            <h4>In Sintesi</h4>

            <p>
                Immagina di avere una funzione Python che fa dei calcoli matematici usando array NumPy (o meglio, <code><a href="https://jax.readthedocs.io/en/latest/jax.numpy.html" target="_blank">jax.numpy</a></code>). Quando chiedi a JAX di fare qualcosa di "speciale" con questa funzione (come compilarla per la velocità con <code><a href="https://jax.readthedocs.io/en/latest/jax.html#jax.jit" target="_blank">jax.jit</a></code> o calcolarne il gradiente con <code><a href="https://jax.readthedocs.io/en/latest/jax.html#jax.grad" target="_blank">jax.grad</a></code>), JAX non esegue immediatamente la tua funzione Python nel modo tradizionale.
                Invece, JAX fa il tracing (tracciamento) della funzione. La prima volta la esegue simbolicamente, ma invece di usare i valori numerici effettivi degli input, usa degli oggetti speciali chiamati tracer. Questi tracer sono come dei segnaposto che registrano le informazioni sulla forma (shape) e sul tipo di dati (dtype) degli array, ma non il loro valore concreto.
                Man mano che la funzione viene eseguita con questi tracer, JAX non esegue le operazioni matematiche vere e proprie. Invece, registra la sequenza di operazioni fondamentali di JAX (chiamate primitive) che vengono applicate ai tracer. Ad esempio, se la tua funzione fa y = x + 1, JAX registra un'operazione di "addizione".
                Il risultato di questo processo di registrazione è una rappresentazione intermedia della tua funzione, chiamata jaxpr (JAX Program Representation). La jaxpr è una descrizione pura e funzionale del calcolo, indipendente dal codice Python originale e dai suoi dettagli implementativi (come i cicli for di Python, che vengono "srotolati" durante il tracing). È essenzialmente un grafo computazionale statico.
            </p>
            
            <p>Questa architettura dà a JAX diverse caratteristiche uniche rispetto ad altri framework di deep learning. La sua capacità di trasformare le funzioni in modo componibile (applicando più trasformazioni in sequenza) e la sua integrazione con l'ecosistema NumPy lo rendono particolarmente adatto per la ricerca e per compiti che richiedono alta prestazione computazionale.</p>
            
            <h4>PERCHE' INSISTERE SULLA PROGRAMMAZIONE FUNZIONALE E L'IMMUTABILITA'</h4>
            <p>
                Le motivazioni principali per cui JAX risponde a queste, talvolta strette, 
                logiche e paradigmi sono l'ottimizzazione e la velocità. L'obiettivo finale è offire in Python, un linguaggio interpretato e lento, 
                la possibilità di compilare parti di codice, per tenerle in cache e riusarle ripetetutamente e velocemente. La cache è una memoria molto veloce, 
                che è utile sfruttare quando i calcoli che si devono fare sono sempre gli stessi, non cambiano il proprio stato, il proprio tipo e le proprie dimensioni.
                Se si dovesse verificare un continuo cambio di stato, il codice dovrebbe essere ricompilato continuamente causando un rallentamento spaventoso dell'esecuzione.
                Viene naturale quindi adottare una filosofia come quella della programmazione funzionale che ci dà il grosso vantaggio di poter fare delle assunzioni forti sui dati
                e sulle funzioni che operano su questi dati, e ancor di più sulla loro immutabilità. In conclusione, con un codice ed una computazione statici l'ottimizzazione diventa
                praticabile, scalabile ed efficiente. 
            </p>

        </div>

        <!-- SEZIONE: Ecosystem di JAX -->
        <div class="content-section" id="jax-ecosystem">
            <h2>L'Ecosistema di JAX</h2>
            
            <p>
                JAX è uno strumento potente che fornisce al programmatore numerosi mattoncini con cui poter costruire e sperimentare nuove idee.
                Dover costruire un'ottimizzatore o un layer o una funzione di loss possono presentare numerose peculiarità tecniche non banali (vedi: overflow nella funzione softmax) che possono
                rallentare di molto gli esperimenti di un ricercatore (non siamo tutti dei programmatori esperti), per questo JAX è considerato un framework
                più complicato di altri. Per sopperire a questa difficoltà la community ha generato un fiorente ecosistema di librerie che estendono le sue funzionalità di base per applicazioni comuni e/o specifiche.
                Alcune delle librerie più importanti costruite su JAX:
            </p>
            
            <div class="library-cards">
                <a href="https://flax.readthedocs.io/" class="library-card" target="_blank">
                    <div class="card-image">
                        <img src="../../images/flax-logo.png" alt="Flax Logo" onerror="this.src='../../images/placeholder.png'">
                    </div>
                    <div class="card-content">
                        <h3>Flax</h3>
                        <p>Framework flessibile per l'addestramento di reti neurali in JAX. Fornisce astrazioni di alto livello per la definizione di modelli e l'implementazione di loop di addestramento mantenendo la flessibilità di JAX.</p>
                    </div>
                </a>
                
                <a href="https://optax.readthedocs.io/" class="library-card" target="_blank">
                    <div class="card-image">
                        <img src="../../images/optax-logo.png" alt="Optax Logo" onerror="this.src='../../images/placeholder.png'">
                    </div>
                    <div class="card-content">
                        <h3>Optax</h3>
                        <p>Libreria per l'ottimizzazione in JAX che fornisce implementazioni di algoritmi di ottimizzazione come SGD, Adam, e RMSProp. Supporta la composizione di trasformazioni del gradiente per costruire ottimizzatori personalizzati.</p>
                    </div>
                </a>
                
                <a href="https://blackjax-devs.github.io/blackjax/" class="library-card" target="_blank">
                    <div class="card-image">
                        <img src="../../images/blackjax-logo.png" alt="BlackJAX Logo" onerror="this.src='../../images/placeholder.png'">
                    </div>
                    <div class="card-content">
                        <h3>BlackJAX</h3>
                        <p>Libreria per l'inferenza bayesiana in JAX. Implementa metodi di campionamento MCMC (Markov Chain Monte Carlo) avanzati per applicazioni di statistica bayesiana e apprendimento automatico probabilistico.</p>
                    </div>
                </a>
            </div>
        </div>
    </div>
    
    <footer>
        <div class="container">
            <p>© 2025 - Guida alle Librerie per Reti Neurali</p>
        </div>
    </footer>
    
   
</body>
</html>